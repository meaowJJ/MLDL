{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb894973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2338b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측이 y1일때 MSE :  0.0195\n",
      "예측이 y2일때 MSE :  0.1295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return np.sum((y - t) ** 2) / len(y)\n",
    "\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y1 = [0.1, 0.0, 0.6, 0.0, 0.05, 0.1, 0.05, 0.1, 0.0, 0.0]\n",
    "y2 = [0.1, 0.1, 0.05, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "print(\"예측이 y1일때 MSE : \", round(mean_squared_error(np.array(y1), np.array(t)), 4))\n",
    "print(\"예측이 y2일때 MSE : \", round(mean_squared_error(np.array(y2), np.array(t)), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c689fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측이 y1일때 CEE :  0.5108\n",
      "예측이 y2일때 CEE :  2.9957\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y1 = [0.1, 0.0, 0.6, 0.0, 0.05, 0.1, 0.05, 0.1, 0.0, 0.0]\n",
    "y2 = [0.1, 0.1, 0.05, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "\n",
    "print(\"예측이 y1일때 CEE : \", round(cross_entropy_error(np.array(y1), np.array(t)), 4))\n",
    "print(\"예측이 y2일때 CEE : \", round(cross_entropy_error(np.array(y2), np.array(t)), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917fa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니 배치용 CEE\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    \n",
    "    return -np.sum(t * np.log(y)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae08e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train 형성 :  (60000, 784)\n",
      "y_train 형성 :  (60000, 10)\n",
      "train data 크기에서 Mini-Batch 수만큼 랜덤하게 추출한 값 : \n",
      "[ 5211 52960  1777 46666 55192 28529 51080 48293  3017 51528]\n",
      "Mini-Batch 처리된 x_train : \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Mini-Batch 처리된 t_train : \n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)\n",
    "\n",
    "print(\"x_train 형성 : \", x_train.shape)\n",
    "print(\"y_train 형성 : \", t_train.shape)\n",
    "\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "print(\"train data 크기에서 Mini-Batch 수만큼 랜덤하게 추출한 값 : \", batch_mask, sep = \"\\n\")\n",
    "print(\"Mini-Batch 처리된 x_train : \", x_batch, sep = \"\\n\")\n",
    "print(\"Mini-Batch 처리된 t_train : \", t_batch, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3842fb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 5에서의 수치 미분 결과 :  1.0999999999983245\n",
      "x = 10에서의 수치 미분 결과 :  2.099999999991553\n"
     ]
    }
   ],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return ( f(x + h) - f(x - h) ) / (2 * h)\n",
    "\n",
    "def function_1(x):\n",
    "    return 0.1 * x ** 2 + 0.1 * x\n",
    "\n",
    "print(\"x = 5에서의 수치 미분 결과 : \", numerical_diff(function_1, 5))\n",
    "print(\"x = 10에서의 수치 미분 결과 : \", numerical_diff(function_1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12eae3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 = 3, x1 = 4에서의 x0에 대한 편미분 결과 :  516.0000003616005\n"
     ]
    }
   ],
   "source": [
    "def partial_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return ( f(x + h) - f(x - h) ) / (2 * h)\n",
    "\n",
    "def function_1(x0):\n",
    "    x1 = 4\n",
    "    return 3 * (x0 ** 4) + 2 * (x0 ** 2) * (x1 ** 2) + 7 * (x1 ** 4)\n",
    "\n",
    "print(\"x0 = 3, x1 = 4에서의 x0에 대한 편미분 결과 : \", partial_diff(function_1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78495049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 = 3, x1 = 4에서의 x1에 대한 편미분 결과 :  2048.0000011207267\n"
     ]
    }
   ],
   "source": [
    "def partial_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return ( f(x + h) - f(x - h) ) / (2 * h)\n",
    "\n",
    "def function_2(x1):\n",
    "    x0 = 4\n",
    "    return 3 * (x0 ** 4) + 2 * (x0 ** 2) * (x1 ** 2) + 7 * (x1 ** 4)\n",
    "\n",
    "print(\"x0 = 3, x1 = 4에서의 x1에 대한 편미분 결과 : \", partial_diff(function_2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "116c1fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 = 3, x1 = 4에서의 기울기 :  [ 516.00000036 1936.00000112]\n"
     ]
    }
   ],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        # f(x + h) 계산\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x - h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2 * h)\n",
    "        # 값 복원\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def function_2(x):\n",
    "    return 3 * (x[0] ** 4) + 2 * (x[0] ** 2) * (x[1] ** 2) + 7 * (x[1] ** 4)\n",
    "\n",
    "print(\"x0 = 3, x1 = 4에서의 기울기 : \", numerical_gradient(function_2, np.array([3.0, 4.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3fc7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate가 10.0일 때 경사하강법을 적용한 최종 W 위치 :  [-9.37416128e+13  2.05109945e+15]\n",
      "Learning rate가 0.001일 때 경사하강법을 적용한 최종 W 위치 :  [-0.58538933  0.35407636]\n",
      "Learning rate가 0.00000001일 때 경사하강법을 적용한 최종 W 위치 :  [-2.99948419  3.99806535]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def gradient_descent(f, init_w, learning_rate, step_num):\n",
    "    w = init_w\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, w)\n",
    "        w -= learning_rate * grad\n",
    "        \n",
    "    return w\n",
    "\n",
    "def function_2(x):\n",
    "    return 3 * (x[0] ** 4) + 2 * (x[0] ** 2) * (x[1] ** 2) + 7 * (x[1] ** 4)\n",
    "\n",
    "print(\"Learning rate가 10.0일 때 경사하강법을 적용한 최종 W 위치 : \", gradient_descent(function_2, np.array([-3.0, 4.0]), 10.0, 100))\n",
    "print(\"Learning rate가 0.001일 때 경사하강법을 적용한 최종 W 위치 : \", gradient_descent(function_2, np.array([-3.0, 4.0]), 0.001, 100))\n",
    "print(\"Learning rate가 0.00000001일 때 경사하강법을 적용한 최종 W 위치 : \", gradient_descent(function_2, np.array([-3.0, 4.0]), 1e-8, 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
